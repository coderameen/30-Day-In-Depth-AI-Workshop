{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAG-nrNjo-xw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epoch_count = 50\n",
        "noise_dim = 100\n",
        "n_class = 10\n",
        "tags = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
        "img_size = 32"
      ],
      "metadata": {
        "id": "izvLzozMpL1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (_, _) = cifar10.load_data()\n",
        "\n",
        "X_train = (X_train - 127.5) / 127.5\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)"
      ],
      "metadata": {
        "id": "AlyNU_QSpNt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(2,2))\n",
        "idx = np.random.randint(0,len(X_train))\n",
        "img = image.array_to_img(X_train[idx], scale=True)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(tags[y_train[idx][0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dV1CPiazpPTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def discriminator_loss(real, fake):\n",
        "\treal_loss = bce_loss(tf.ones_like(real), real)\n",
        "\tfake_loss = bce_loss(tf.zeros_like(fake), fake)\n",
        "\ttotal_loss = real_loss + fake_loss\n",
        "\treturn total_loss\n",
        "\n",
        "def generator_loss(preds):\n",
        "\treturn bce_loss(tf.ones_like(preds), preds)"
      ],
      "metadata": {
        "id": "06IS4vNmpRQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "g_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)"
      ],
      "metadata": {
        "id": "rJhqKzlCpSop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\tin_label = tf.keras.layers.Input(shape=(1,))\n",
        "\tli = tf.keras.layers.Embedding(n_class, 50)(in_label)\n",
        "\n",
        "\tn_nodes = 8 * 8\n",
        "\tli = tf.keras.layers.Dense(n_nodes)(li)\n",
        "\tli = tf.keras.layers.Reshape((8, 8, 1))(li)\n",
        "\n",
        "\tin_lat = tf.keras.layers.Input(shape=(noise_dim,))\n",
        "\tn_nodes = 128 * 8 * 8\n",
        "\tgen = tf.keras.layers.Dense(n_nodes)(in_lat)\n",
        "\tgen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
        "\tgen = tf.keras.layers.Reshape((8, 8, 128))(gen)\n",
        "\n",
        "\tmerge = tf.keras.layers.Concatenate()([gen, li])\n",
        "\n",
        "\tgen = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(merge)\n",
        "\tgen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "\tgen = tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(gen)\n",
        "\tgen = tf.keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "\tout_layer = tf.keras.layers.Conv2D(3, (8, 8), activation='tanh', padding='same')(gen)\n",
        "\n",
        "\tmodel = Model([in_lat, in_label], out_layer)\n",
        "\treturn model\n",
        "\n",
        "g_model = build_generator()\n",
        "g_model.summary()"
      ],
      "metadata": {
        "id": "f6dD0V8ppUDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\tin_label = tf.keras.layers.Input(shape=(1,))\n",
        "\tli = tf.keras.layers.Embedding(n_class, 50)(in_label)\n",
        "\n",
        "\tn_nodes = img_size * img_size\n",
        "\tli = tf.keras.layers.Dense(n_nodes)(li)\n",
        "\tli = tf.keras.layers.Reshape((img_size, img_size, 1))(li)\n",
        "\n",
        "\tin_image = tf.keras.layers.Input(shape=(img_size, img_size, 3))\n",
        "\n",
        "\tmerge = tf.keras.layers.Concatenate()([in_image, li])\n",
        "\n",
        "\tfe = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
        "\tfe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "\tfe = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "\tfe = tf.keras.layers.LeakyReLU(alpha=0.2)(fe)\n",
        "\n",
        "\tfe = tf.keras.layers.Flatten()(fe)\n",
        "\tfe = tf.keras.layers.Dropout(0.4)(fe)\n",
        "\n",
        "\tout_layer = tf.keras.layers.Dense(1, activation='sigmoid')(fe)\n",
        "\n",
        "\tmodel = Model([in_image, in_label], out_layer)\n",
        "\treturn model\n",
        "\n",
        "d_model = build_discriminator()\n",
        "d_model.summary()\n"
      ],
      "metadata": {
        "id": "Lr5xCe86pVdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        "\tdiscriminator.trainable = False\n",
        "\tnoise, label = generator.input\n",
        "\timg = generator.output\n",
        "\n",
        "\tvalidity = discriminator([img, label])\n",
        "\tmodel = Model([noise, label], validity)\n",
        "\treturn model\n",
        "\n",
        "gan_model = build_gan(g_model, d_model)\n",
        "gan_model.summary()"
      ],
      "metadata": {
        "id": "Yu3kFeIspYI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_model.compile(loss=generator_loss, optimizer=g_optimizer)\n",
        "d_model.compile(loss=discriminator_loss, optimizer=d_optimizer)\n",
        "gan_model.compile(loss=generator_loss, optimizer=g_optimizer)"
      ],
      "metadata": {
        "id": "iQxAZmE3pZdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(dataset, epochs, batch_size):\n",
        "\tfor epoch in range(epochs):\n",
        "\t\tfor batch in dataset:\n",
        "\t\t\treal_images, labels = batch\n",
        "\t\t\tbatch_size = real_images.shape[0]\n",
        "\n",
        "\t\t\tnoise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "\t\t\tgen_labels = np.random.randint(0, n_class, batch_size).reshape(-1, 1)\n",
        "\t\t\tgen_images = g_model.predict([noise, gen_labels])\n",
        "\n",
        "\t\t\td_loss_real = d_model.train_on_batch([real_images, labels], np.ones((batch_size, 1)))\n",
        "\t\t\td_loss_fake = d_model.train_on_batch([gen_images, gen_labels], np.zeros((batch_size, 1)))\n",
        "\t\t\td_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "\t\t\tnoise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "\t\t\tvalid_y = np.ones((batch_size, 1))\n",
        "\t\t\tg_loss = gan_model.train_on_batch([noise, gen_labels], valid_y)\n",
        "\n",
        "\t\tprint(f\"{epoch + 1}/{epochs}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
        "\t\tif (epoch + 1) % 10 == 0:\n",
        "\t\t\tsave_images(epoch, noise, gen_labels)\n",
        "\n",
        "train_gan(dataset, epoch_count, batch_size)"
      ],
      "metadata": {
        "id": "ygKnXfddpaup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(epoch, noise, labels):\n",
        "\tgen_images = g_model.predict([noise, labels])\n",
        "\tgen_images = 0.5 * gen_images + 0.5  # Rescale images to [0, 1]\n",
        "\n",
        "\tfig, axs = plt.subplots(4, 4, figsize=(4, 4))\n",
        "\taxs = axs.flatten()\n",
        "\tfor img, label, ax in zip(gen_images, labels, axs):\n",
        "\t\tax.imshow(img)\n",
        "\t\tax.axis('off')\n",
        "\t\tax.set_title(tags[label[0]])\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "ZHxVPp-JpcTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}