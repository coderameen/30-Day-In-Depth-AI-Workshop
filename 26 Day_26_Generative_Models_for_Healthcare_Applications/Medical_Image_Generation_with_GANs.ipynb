{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Medical Image Generation with GANs",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'chest-xray-pneumonia:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F17810%2F23812%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240917%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240917T040732Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D107db21451ae23aa146efc0788bd0fe59417421f062fe3b626f1ebf5625081f4c94fc9c778349eabaa2cfe4010e4543759833302f35a32260f0d7d55346f960e5f9b99b6185b52741018f5273c726784b8414b622197ee82b4fea652f24206dff474c3ba46f25e2ebd5cfff43701837d01d93405afb5abc9dc53c9b40566fb9f7ea9bdb6eb5407aa8f48097122530d6933c6cc6fe10f421a8831c034fc414ed761227cee3bb38d9f2715bea8c9eaaac163e331ab24f860702fe8f893f658e19383456d2392d8c67bb1cebfb27c70287a36e43bc796d83c4e07b9a342728edb01f336f7ca6c61b7c8d09c81b1cd2ef5fe0fafcc1c5e35bfca9684a1c70204f459'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "H0lpeuKlKidk"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:59538bc3-73cd-4f39-93e1-f5d506f11cde.png)\n",
        "![image.png](attachment:8931759e-6b2b-4cf4-808a-39c61aafeba2.png)\n",
        "\n",
        "This notebook uses Generative Adversarial Networks (GANs) to generate synthetic pneumonia-positive X-ray images. The goal is to generate hyperrealistic images that can be used to augment the existing dataset for better model training. The current demo has yet to achieve this goal, but the plan is to explore the application of Generative Adversarial Networks (GANs) to generate new and accurate medical images in the future.\n",
        "\n",
        "**The primary aim is to train the GAN to generate highly realistic synthetic X-ray images that closely resemble the real ones in the dataset. These synthetic images can then be utilized for future data augmentation.**\n",
        "\n",
        "As of the current demonstration, the generated images might not yet reach clinically accurate levels. However, **a more complex architecture has the potential to generate highly realistic and accurate pneumonia-positive X-ray images.** The synthetic images produced can effectively augment existing datasets of pneumonia-positive X-rays, leading to improved accuracy and performance of pneumonia detection models\n",
        "\n",
        "The main takeaway from this project is the potential of GANs in medical image generation for data augmentation, enabling the development of more effective diagnostic tools for pneumonia and other medical conditions.\n",
        "\n",
        "\n",
        "# Configuration Details:\n",
        "\n",
        "* GPU Accelerator: T4 (2 units)\n",
        "* Dataset: **[Chest X-ray Pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)**\n",
        "* Dataset Size: 3875\n",
        "* Output Image Size: 512x512\n",
        "* Optimizer: Adam\n",
        "* Learning Rate: 0.0002\n",
        "* Loss Function: Binary Crossentropy\n",
        "* Generator: 1 Dense, 6 Convolutional Transpose, 1 Convolutional\n",
        "* Discriminator: 4 Convolutional, 4 MaxPooling, 1 Flatten, 2 Dense"
      ],
      "metadata": {
        "id": "4JMBFNhCKidz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "wTr_jo_7Kid3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Dense, BatchNormalization, Conv2D, Conv2DTranspose, ReLU, LeakyReLU, Flatten, MaxPooling2D, Dropout, Reshape"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "UpAROaXZKid4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Initialization"
      ],
      "metadata": {
        "id": "Gi07IdONKid6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZQ8gP46NKid7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "qtGFt2gLKid-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initially I went for 128*128, later decided to go with 512*512 image size\n",
        "BUFFER_SIZE = 64000\n",
        "BATCH_SIZE = 32*strategy.num_replicas_in_sync\n",
        "batch_size = BATCH_SIZE\n",
        "EPOCHS = 50\n",
        "latent_dim = 128\n",
        "input_size = [256*2, 256*2, 3]\n",
        "image_size = (256*2, 256*2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iocGC-OfKid_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "uuu5ax2mKieA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataset with ImageDataGenerator is way simpler than other methods\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "# Initially created the datatest with some augmentation, then realised, bad idea.\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True\n",
        ")\n",
        "\n",
        "image_directory = '/kaggle/input/chest-xray-pneumonia/chest_xray'\n",
        "\n",
        "dataset= datagen.flow_from_directory(\n",
        "    os.path.join(image_directory, 'train'),\n",
        "    classes=['PNEUMONIA'],\n",
        "    target_size=image_size,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "U4KYqy2KKieB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sXQjr-QjKieC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Model"
      ],
      "metadata": {
        "id": "Qmec5eNEKieD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_model():\n",
        "    #in case you get OOM error, change the filter size, set it to a smaller value, 28 for example\n",
        "    model = Sequential([\n",
        "        Input(shape = (latent_dim,)),\n",
        "        Dense(8*8*256),\n",
        "        Reshape((8, 8, 256)),\n",
        "        Conv2DTranspose(128*2, kernel_size = 4, strides = 2, padding = 'same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*3, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*3, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*4, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*5, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2DTranspose(128*6, kernel_size=4, strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Conv2D(3, kernel_size =4, padding = 'same', activation = 'sigmoid')\n",
        "    ],\n",
        "        name = \"generator\"\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "-3CBVpICKieD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator Model"
      ],
      "metadata": {
        "id": "vDs4BEwUKieE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disc_model():\n",
        "    #in case you get OOM error, change the filter size, set it to a smaller value, 256 or lower for example\n",
        "    #keep reducing that value untill the error goes away.\n",
        "    model = Sequential([\n",
        "        Input(shape = input_size),\n",
        "        Conv2D(256, kernel_size = 4, strides= 2, padding = 'same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides = 2),\n",
        "        Conv2D(256*2, kernel_size=4, strides=2, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides=2),\n",
        "        Conv2D(256*3, kernel_size=4, strides=2, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides=2),\n",
        "        Conv2D(256*4, kernel_size=4, strides=2, padding='same'),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        MaxPooling2D(strides=2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(256*4),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation = 'sigmoid')\n",
        "    ],\n",
        "        name = \"discriminator\"\n",
        "    )\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "VHY51w6jKieE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    #In order to utilize mutliple GPU,\n",
        "    #you  must declare model, optimizers and checkpoints inside of a scope\n",
        "    generator = gen_model()\n",
        "    discriminator = disc_model()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "rGnWkNJ3KieF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "NXlrQK1lKieG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper funtion to help us with loadidng images in batches\n",
        "def image_loader(generator):\n",
        "    for images, labels in generator:\n",
        "        yield images, labels"
      ],
      "metadata": {
        "trusted": true,
        "id": "Fx-7tpjFKieG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN with Custom Traning Step"
      ],
      "metadata": {
        "id": "IeLOwn9aKieG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gan model with custom gradient calculation\n",
        "class Gan(Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, disc_opt, gen_opt, loss_function):\n",
        "        super().compile()\n",
        "        self.disc_opt = disc_opt\n",
        "        self.gen_opt = gen_opt\n",
        "        self.loss_function = loss_function\n",
        "        self.disc_loss_metric = tf.keras.metrics.Mean(name = \"disc_loss\")\n",
        "        self.gen_loss_metric = tf.keras.metrics.Mean(name = \"gen_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.disc_loss_metric, self.gen_loss_metric]\n",
        "\n",
        "    #custom training step\n",
        "    def train_step(self, data):  # Modify the function to accept labels separately\n",
        "        real_images, real_labels = data\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Fake image decoding\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Concatenate the real and fake labels\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "\n",
        "        labels += 0.05*tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            disc_loss = self.loss_function(labels, predictions)\n",
        "\n",
        "        grads  = tape.gradient(disc_loss, self.discriminator.trainable_weights)\n",
        "        self.disc_opt.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape = (batch_size,self.latent_dim))\n",
        "\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "\n",
        "            gen_loss = self.loss_function(misleading_labels, predictions)\n",
        "\n",
        "        grads = tape.gradient(gen_loss, self.generator.trainable_weights)\n",
        "        self.gen_opt.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        self.disc_loss_metric.update_state(disc_loss)\n",
        "        self.gen_loss_metric.update_state(gen_loss)\n",
        "        return{\n",
        "            \"disc_loss\": self.disc_loss_metric.result(),\n",
        "            \"gen_loss\": self.gen_loss_metric.result()\n",
        "        }\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "O5uO_T9oKieH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper functiont to generated a image using current generator model\n",
        "#It was initially desgined to use inside of a  callback, but can be used outside of that too.\n",
        "#Use 1 as defalut parameter when calling independently.\n",
        "def gen_images(current_epoch):\n",
        "    noise = tf.random.normal([2, latent_dim])\n",
        "    num_of_sample = 2\n",
        "    generated_images = generator(noise, training = False)\n",
        "    figure = plt.figure(figsize=(20,20))\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(2, 2,i+1)\n",
        "        plt.imshow(generated_images[i, :, :, 0, ], cmap = 'gray')\n",
        "        plt.title(f\"After epoch {current_epoch}\")\n",
        "        plt.axis('off')\n",
        "    plt.savefig('After epochs{:04d}.png'.format(current_epoch))\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ii3xR1mgKieI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks"
      ],
      "metadata": {
        "id": "-b2mXXKwKieI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#callbacks. We are showing progress of gan and also saving samples after each epochs\n",
        "class Gan_Callback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, num_images=2, latent_dim = 128):\n",
        "        self.num_images = num_images\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs =None):\n",
        "        latent_vectors = tf.random.normal(shape = (self.num_images, latent_dim))\n",
        "        generated_images = self.model.generator(latent_vectors)\n",
        "        generated_images *=255\n",
        "        generated_images.numpy()\n",
        "        figure = plt.figure(figsize=(10,10))\n",
        "        for i in range(generated_images.shape[0]):\n",
        "            plt.subplot(2, 2,i+1)\n",
        "            plt.imshow(generated_images[i, :, :, 0, ], cmap='gray')\n",
        "            plt.title(f\"After epoch {epoch+1}\")\n",
        "            plt.axis('off')\n",
        "        plt.savefig('After epochs{:04d}.png'.format(epoch+1))\n",
        "        plt.show()\n",
        "        if(epoch % 10 ==0):\n",
        "            self.model.generator.save('/kaggle/working/gen.h5')\n",
        "            self.model.discriminator.save('/kaggle/working/disc.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "JhzguBUNKieJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    #In order to utilize mutliple GPU,\n",
        "    #you  must declare model, optimizers and checkpoints inside of a scope\n",
        "    gan = Gan(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "    gan.compile(\n",
        "        disc_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "        gen_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "        # Parallel gpu computing won't work unless  we pass reduction=tf.keras.losses.Reduction.NONE as a parameter too.\n",
        "        loss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE),\n",
        "    )\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "YppVh_FrKieJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning"
      ],
      "metadata": {
        "id": "K8lC2Vx5KieK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#actual traing begins here\n",
        "history = gan.fit(\n",
        "    image_loader(dataset),\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=len(dataset),\n",
        "    callbacks=[Gan_Callback(num_images=4, latent_dim=latent_dim)]\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "jbkW6GXWKieK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlFK0H8eKieK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}